# HARBOR Auto-Annotator Service
# AI-powered annotation pipeline using YOLOv11, SAM3, Whisper, CLIP

[project]
name = "harbor-auto-annotator"
version = "0.1.0"
description = "Auto-annotation pipeline for HARBOR using YOLOv11, SAM3, Whisper, CLIP"
requires-python = ">=3.10"
dependencies = [
    # API Framework
    "fastapi>=0.109.0",
    "uvicorn>=0.27.0",
    "pydantic>=2.5.0",
    "python-dotenv>=1.0.0",
    "httpx>=0.26.0",
    
    # AI Models
    "ultralytics>=8.3.0",        # YOLOv11
    "openai-whisper>=20231117",   # Whisper
    "openai>=1.10.0",             # CLIP via OpenAI
    "torch>=2.1.0",
    "torchvision>=0.16.0",
    
    # Image/Video Processing
    "opencv-python>=4.8.0",
    "Pillow>=10.0.0",
    "numpy>=1.24.0",
    
    # Utilities
    "aiofiles>=23.2.0",
    "redis>=5.0.0",               # Job queue
]

[project.optional-dependencies]
dev = [
    "pytest>=7.4.0",
    "pytest-asyncio>=0.23.0",
    "black>=24.0.0",
    "ruff>=0.1.0",
]

# For local SAM (optional, uses Roboflow API by default)
sam = [
    "segment-anything>=1.0",
]

[build-system]
requires = ["hatchling"]
build-backend = "hatchling.build"

[tool.black]
line-length = 100
target-version = ["py310"]

[tool.ruff]
line-length = 100
select = ["E", "F", "I", "N", "W"]
